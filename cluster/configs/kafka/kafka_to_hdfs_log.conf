#定义组件
a2.sources=r1
a2.channels=c1
a2.sinks=k1

#配置source1
a2.sources.r1.type = org.apache.flume.source.kafka.KafkaSource
a2.sources.r1.batchSize = 5000
a2.sources.r1.batchDurationMillis = 2000
a2.sources.r1.kafka.bootstrap.servers = master01:9092
a2.sources.r1.kafka.topics=gh_activity

#配置channel
a2.channels.c1.type = file
a2.channels.c1.checkpointDir = /opt/module/flume/checkpoint/behavior1
a2.channels.c1.dataDirs = /opt/module/flume/data/behavior1
a2.channels.c1.maxFileSize = 2146435071
a2.channels.c1.capacity = 1000000
a2.channels.c1.keep-alive = 6

#配置sink
a2.sinks.k1.type = hdfs
a2.sinks.k1.hdfs.path = /testlog/gh_activity
a2.sinks.k1.hdfs.filePrefix = activity
a2.sinks.k1.hdfs.fileSuffix = .json
a2.sinks.k1.hdfs.round = true
a2.sinks.k1.hdfs.rollInterval = 0
a2.sinks.k1.hdfs.rollSize = 134217728
a2.sinks.k1.hdfs.rollCount = 0

#控制输出文件类型
# a2.sinks.k1.hdfs.fileType = CompressedStream
# a2.sinks.k1.hdfs.codeC = gzip

a2.sinks.k1.hdfs.fileType = DataStream
a2.sinks.k1.hdfs.writeFormat =Text

#组装 
a2.sources.r1.channels = c1
a2.sinks.k1.channel = c1
